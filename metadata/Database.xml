
<root>

    <sir>
        <name>transformers</name>
        <source>https://github.com/Liang813/transformers</source>
        <bug>
            <id>transformers1962</id>
            <errormessage>ValueError</errormessage>
            <describe>TFBertModel ValueError: Tried to convert 'dims' to a tensor and failed. Error: Cannot convert a partially known TensorShape to a Tensor</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>transformers1962-buggy.sh</buggytestCmd>
                <buggycommit>adb5c79ff2ffcd2e4a43a12f082cca55f7630a96</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>transformers1962-fix.sh</fixtestCmd>
                <fixcommit>4a666885b501ed6bfd344ec2c4c16d80da8aab79</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>transformers</name>
        <source>https://github.com/Liang813/transformers</source>
        <bug>
            <id>transformers1418</id>
            <errormessage>TypeError</errormessage>
            <describe>The issue is due to implementation difference between Tensorflow and Pytorch DistillBERT. Tensorflow implementation doesn't have loss calculation inside call, but We do in forward for Pytorch. </describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>transformers1418-buggy.sh</buggytestCmd>
                <buggycommit>c1689ac30164d190f366d95d1f5153af53e66355</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>transformers1418-fix.sh</fixtestCmd>
                <fixcommit>a9f6d3f101556f0fd7f07e6ef9c22f1430b68e52</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>transformers</name>
        <source>https://github.com/Liang813/transformers</source>
        <bug>
            <id>transformers1152</id>
            <errormessage>TypeError</errormessage>
            <describe>List does not match tuple</describe>
            <rootCause>1</rootCause>
            <type>type mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>transformers1152-buggy.sh</buggytestCmd>
                <buggycommit>caf1d116a62a324a2b0ccfd92ca6c095d5368dde</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>transformers1152-fix.sh</fixtestCmd>
                <fixcommit>07e21307b6b16350425ea08790c7e20c081a3b3f</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>allennlp</name>
        <source>https://github.com/Liang813/allennlp</source>
        <bug>
            <id>allennlp3721</id>
            <errormessage>TypeError</errormessage>
            <describe>ListField and MultilabelField are used incorrectly for sequence prediction using multi-label data.</describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>allennlp3721-buggy.sh</buggytestCmd>
                <buggycommit>bae0c55e8c447811d9fa13f1c48f3e2576ab0dcc</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>allennlp3721-fix.sh</fixtestCmd>
                <fixcommit>beb07be50a8c0267b1ff398793ecde1194a538fe</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>allennlp</name>
        <source>https://github.com/Liang813/allennlp</source>
        <bug>
            <id>allennlp4612</id>
            <errormessage>None</errormessage>
            <describe>NaN grads appear when an empty string is given</describe>
            <rootCause>1</rootCause>
            <type>zero division</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>allennlp4612-buggy.sh</buggytestCmd>
                <buggycommit>e840a589afc4bfdac0165a8650145259a7603807</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>allennlp4612-fix.sh</fixtestCmd>
                <fixcommit>b2bb2a364320142c733e306df1d04e4e8237150d</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>pytorch-lightning</name>
        <source>https://github.com/Liang813/pytorch-lightning</source>
        <bug>
            <id>pytorch-lightning2386</id>
            <errormessage>TypeError</errormessage>
            <describe>The class does not choose to use the position parameter, but passes it the position parameter</describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>pytorch-lightning2386-buggy.sh</buggytestCmd>
                <buggycommit>861a73be12ef17214bb0ed49aabc9f48a80fde16</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>pytorch-lightning2386-fix.sh</fixtestCmd>
                <fixcommit>ae8be9efc13a914cbd763f021c5d289ca94bbdcf</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>botorch</name>
        <source>https://github.com/Liang813/botorch</source>
        <bug>
            <id>botorch162</id>
            <errormessage>None</errormessage>
            <describe>inv_transform was crapping out when drawing a large number of samples because the base sample was exactly 1.0( see issue #161). While we were previously subtracting off a small number (1e-10), this number wasn't sufficient. I found that (1-e6) was the smallest base 10 number we could subtract off to get rid of the -inf.</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>botorch162-buggy.sh</buggytestCmd>
                <buggycommit>8b17815b736cf0b95cc6a8c0ad9d8867a2d541bc</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>botorch162-fix.sh</fixtestCmd>
                <fixcommit>c15c8f261571d36a8f6e4947313e4e4f4365c3a3</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>ggnn.pytorch</name>
        <source>https://github.com/Liang813/ggnn.pytorch</source>
        <bug>
            <id>ggnn.pytorch9</id>
            <errormessage>IndexError</errormessage>
            <describe>Indexing 0-dim tensor error</describe>
            <rootCause>1</rootCause>
            <type>IndexError</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>ggnn.pytorch9-buggy.sh</buggytestCmd>
                <buggycommit>0c7897fe9b05e9b4f9a963ff55bd3ad917ea734e</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>ggnn.pytorch9-fix.sh</fixtestCmd>
                <fixcommit>9c58ca60fd9c389ffd41b7cb4b10cade592344f8</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>fairseq</name>
        <source>https://github.com/Liang813/fairseq</source>
        <bug>
            <id>fairseq1863</id>
            <errormessage>None</errormessage>
            <describe>Speech recognition fails due to NaN if there is an input of size 1</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>fairseq1863-buggy.sh</buggytestCmd>
                <buggycommit>95294bfbb627c7ba140e73ac27c8e98012045916</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>fairseq1863-fix.sh</fixtestCmd>
                <fixcommit>5453e4355b274645074d0068f668ac5bcea9905c</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>seq2seq</name>
        <source>https://github.com/Liang813/seq2seq</source>
        <bug>
            <id>seq2seq95</id>
            <errormessage>ValueError</errormessage>
            <describe>Fix attention scores shape definition</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>seq2seq95-buggy.sh</buggytestCmd>
                <buggycommit>61bd9f7a46577fabc9f98cad6f3ec23cf4034814</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>seq2seq95-fix.sh</fixtestCmd>
                <fixcommit>5a1338603a15848302fb1958ef3c9ef426935654</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>seq2seq</name>
        <source>https://github.com/Liang813/seq2seq</source>
        <bug>
            <id>seq2seq</id>
            <errormessage>AssertionError</errormessage>
            <describe>Fix bug in residual connection dimensions</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>seq2seq-buggy.sh</buggytestCmd>
                <buggycommit>c54a7aba00433743cf960dcc98be6057204179f1</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>seq2seq-fix.sh</fixtestCmd>
                <fixcommit>69cd7e4cffc2ff26b111ccd1ec563b6888cccedb</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>dcgan-completion.tensorflow</name>
        <source>https://github.com/Liang813/seq2seq</source>
        <bug>
            <id>dcgan-completion.tensorflow</id>
            <errormessage>TypeError</errormessage>
            <describe>Arguments to one function are taken into another function</describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>dcgan-completion.tensorflow-buggy.sh</buggytestCmd>
                <buggycommit>bba1b1592bc928c787aa9dc953bcf2cf540b4eb9</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>dcgan-completion.tensorflow-fix.sh</fixtestCmd>
                <fixcommit>e2efc870054836172cbed70dfc08da6fc0ff2e04</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>models</name>
        <source>https://github.com/Liang813/models</source>
        <bug>
            <id>models857</id>
            <errormessage>ValueError</errormessage>
            <describe>Function using error, parameter using parameter sequence using error.</describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>models857-buggy.sh</buggytestCmd>
                <buggycommit>4b53df3cf4f8e15816d5e2d5093ec855fb4e410c</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>models857-fix.sh</fixtestCmd>
                <fixcommit>e93ec37201f5f2116933ae96e505f409ddbf344d</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>sact</name>
        <source>https://github.com/Liang813/sact</source>
        <bug>
            <id>sact1</id>
            <errormessage>ValueError</errormessage>
            <describe>Function using error, parameter using parameter sequence using error.</describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>sact1-buggy.sh</buggytestCmd>
                <buggycommit>10e09ab327ab57f2520ef260b5c57fb523eb2980</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>sact1-fix.sh</fixtestCmd>
                <fixcommit>98a8fd0d623261b32f8b6bcff63c8000a71b1e18</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>models</name>
        <source>https://github.com/Liang813/models</source>
        <bug>
            <id>models1063</id>
            <errormessage>TypeError</errormessage>
            <describe>The assignment of two arguments to the function is reversed</describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>models1063-buggy.sh</buggytestCmd>
                <buggycommit>fdc0c4ab1b039b6085478b36b5cd3cad038941ec</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>models1063-fix.sh</fixtestCmd>
                <fixcommit>5c535343059ceec4b9ca9decdc8c9da8c3e58ced</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>models</name>
        <source>https://github.com/Liang813/models</source>
        <bug>
            <id>models1707</id>
            <errormessage>None</errormessage>
            <describe>This works around a bug in earlier proto versions that automatically infer these values to be integer instead of float.</describe>
            <rootCause>1</rootCause>
            <type>type mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>models1707-buggy.sh</buggytestCmd>
                <buggycommit>434c277677ba973ae6acc21fcc3d616e1bb7f1df</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>models1707-fix.sh</fixtestCmd>
                <fixcommit>c4ba26b4d36ea8d339200bab6bd6fea6fd4af11b</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>models</name>
        <source>https://github.com/Liang813/models</source>
        <bug>
            <id>models23</id>
            <errormessage>None</errormessage>
            <describe>The normalization function was used incorrectly, causing NaN to appear when calculating the loss</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>models23-buggy.sh</buggytestCmd>
                <buggycommit>38079f01d0cdbeb8e3aa6c4ef0a8d5b5c1e4d9a0</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>models23-fix.sh</fixtestCmd>
                <fixcommit>55a34ae564f5ab49adaf98bd4552dcd4bf8f85f3</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>models</name>
        <source>https://github.com/Liang813/models</source>
        <bug>
            <id>models1585</id>
            <errormessage>ValueError</errormessage>
            <describe>Error using resnet_v1 feature extractor</describe>
            <rootCause>1</rootCause>
            <type>API misuse</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>models1585-buggy.sh</buggytestCmd>
                <buggycommit>daf4bf93e3ae6276137a904fb56a32809296df29</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>models1585-fix.sh</fixtestCmd>
                <fixcommit>e76190e83e773875ddfae38339cd299b64e7eda8</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>models</name>
        <source>https://github.com/Liang813/models</source>
        <bug>
            <id>models166</id>
            <errormessage>None</errormessage>
            <describe>Use the tensorflow cross entropy function to prevent nan losses.</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>models166-buggy.sh</buggytestCmd>
                <buggycommit>05630a7578b25390f469b2f91f2c2326e5ed539b</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>models166-fix.sh</fixtestCmd>
                <fixcommit>d8169710322cb6e20be61fef179e66d56d2b1151</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>models</name>
        <source>https://github.com/Liang813/models</source>
        <bug>
            <id>models893</id>
            <errormessage>ValueError</errormessage>
            <describe>Adding to the function inputs in order to match the function distorted_inputs.</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>models893-buggy.sh</buggytestCmd>
                <buggycommit>2cd62f6c6d3cfc95f022b9e04e2c2ef15f538b75</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>models893-fix.sh</fixtestCmd>
                <fixcommit>19c23e72a22bb6d3942f85895e5d2a0fd7410e99</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>TensorFlow-Examples</name>
        <source>https://github.com/Liang813/TensorFlow-Examples</source>
        <bug>
            <id>tensorflow-examples10</id>
            <errormessage>None</errormessage>
            <describe>Author forgot to compute the mean loss over a batch. It is not a problem with small batch size, but it could lead to issues with large batch size, as it leads to unrepresentative cost (NaN) ...</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>TensorFlow-Examples10-buggy.sh</buggytestCmd>
                <buggycommit>844bbfce6d5a872e547fa27c601c5816d4b39f91</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>TensorFlow-Examples10-fix.sh</fixtestCmd>
                <fixcommit>742675db9e3085579b1325b21743fb3a4bc804ab</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>Deep-Learning-TensorFlow</name>
        <source>https://github.com/Liang813/Deep-Learning-TensorFlow</source>
        <bug>
            <id>deep-learning-tensorflow1</id>
            <errormessage>None</errormessage>
            <describe>The learning_rate is not small enough to cause the parameter to explode</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>Deep-Learning-TensorFlow1-buggy.sh</buggytestCmd>
                <buggycommit>907833ab90e27af156484e1aa140ed656e4b4a15</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>Deep-Learning-TensorFlow1-fix.sh</fixtestCmd>
                <fixcommit>b9bc441fdec5e8a5a1c4285d724dd43b327b4cf8</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>Deep-Learning-TensorFlow</name>
        <source>https://github.com/Liang813/Deep-Learning-TensorFlow</source>
        <bug>
            <id>deep-learning-tensorflow5</id>
            <errormessage>None</errormessage>
            <describe>missing tf.nn.softmax() in create_softmax_layer</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>Deep-Learning-TensorFlow5-buggy.sh</buggytestCmd>
                <buggycommit>ded661243a7bf86975e4f29fdf192d7dc4a72770</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>Deep-Learning-TensorFlow5-fix.sh</fixtestCmd>
                <fixcommit>1bcc1efcce5772af15c8e787f21ae60a923e6731</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>Deep-Learning-TensorFlow</name>
        <source>https://github.com/Liang813/Deep-Learning-TensorFlow</source>
        <bug>
            <id>deep-learning-tensorflow0</id>
            <errormessage>None</errormessage>
            <describe>Use tf.nn.softmax() only in the case of cross entropy loss</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>Deep-Learning-TensorFlow0-buggy.sh</buggytestCmd>
                <buggycommit>1bcc1efcce5772af15c8e787f21ae60a923e6731</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>Deep-Learning-TensorFlow0-fix.sh</fixtestCmd>
                <fixcommit>20d1b59e69d4ae56ff9bf0c7263d3f2e47d4cdc9</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>Deep-Learning-TensorFlow</name>
        <source>https://github.com/Liang813/Deep-Learning-TensorFlow</source>
        <bug>
            <id>deep-learning-tensorflow</id>
            <errormessage>None</errormessage>
            <describe>NaN may occur when calculating the cross entropy loss</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>Deep-Learning-TensorFlow-buggy.sh</buggytestCmd>
                <buggycommit>53c69ce3e6af6213e73cff84c675c93c9a2a47f7</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>Deep-Learning-TensorFlow-fix.sh</fixtestCmd>
                <fixcommit>726b371d42e853e61b4deac06ed064a61a619572</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>DCGAN-tensorflow</name>
        <source>https://github.com/Liang813/DCGAN-tensorflow</source>
        <bug>
            <id>dcgan-tensorflow108</id>
            <errormessage>TypeError</errormessage>
            <describe>A result of type int is required, but a result of type float is returned</describe>
            <rootCause>1</rootCause>
            <type>type mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>DCGAN-tensorflow108-buggy.sh</buggytestCmd>
                <buggycommit>9166ef99bf9fcd1d0bf641ae752428bb06903b00</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>DCGAN-tensorflow108-fix.sh</fixtestCmd>
                <fixcommit>3d7395aa4a0663ebb20aa2568ab91f70e555edf0</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>DCGAN-tensorflow</name>
        <source>https://github.com/Liang813/DCGAN-tensorflow</source>
        <bug>
            <id>dcgan-tensorflow17</id>
            <errormessage>ModuleNotFoundError</errormessage>
            <describe>Failing to load data during Training on CelebA</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>DCGAN-tensorflow17-buggy.sh</buggytestCmd>
                <buggycommit>eb2ffe490f61e478227bf539f75ed0b6f9bb1d6b</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>DCGAN-tensorflow17-fix.sh</fixtestCmd>
                <fixcommit>550534e89c93993eadc817af0d68fdb09d82d4c6</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras11657</id>
            <errormessage>TypeError</errormessage>
            <describe>KerasRegressor.predict does not squeeze batch dims,If the input to KerasRegressor.predict() is an array with one example, then the output should be a 1D array with one example, not a 0D array.</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>keras11657-buggy.sh</buggytestCmd>
                <buggycommit>7cd6c59789c8e469c0d3cab6bca7ae3d2d028002</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>keras11657-fix.sh</fixtestCmd>
                <fixcommit>c2d01f5ea69170a2365050368dfa534b75592c06</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras9812</id>
            <errormessage>ValueError</errormessage>
            <describe>Use NASNetLarge，get Error  It only works with shape (331,331,3) but for larger inputs like (640,640,3) does not work again.     But In docs NASNetLarge: 'It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.'</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>keras9812-buggy.sh</buggytestCmd>
                <buggycommit>736b7a705db802d63ddcee1cd0687f806ef2d495</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>keras9812-fix.sh</fixtestCmd>
                <fixcommit>2f1a1780436ee91f44944061e046e43e9719300c</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>GPflow</name>
        <source>https://github.com/Liang813/GPflow</source>
        <bug>
            <id>gpflow813</id>
            <errormessage>ValueError</errormessage>
            <describe>The current implementation of ndiag_mc didn't handle multi-dimensional kwargs Ys .</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>GPflow813-buggy.sh</buggytestCmd>
                <buggycommit>1db48f3a735eb0fba06a7d503f080a7ead512604</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>GPflow813-fix.sh</fixtestCmd>
                <fixcommit>13dd23362cdb30f6478f48f5a7ca4fcab4108580</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras6387</id>
            <errormessage>InvalidArgumentError</errormessage>
            <describe>It seems that the TimeDistributed layer has a similar issue as the Bidirectional layer when passed a layer that requires the learning phase. Seems like wrapper is not taking good care of learning phase.</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>keras6387-buggy.sh</buggytestCmd>
                <buggycommit>7d52af64c03e71bcd23112a7086dc8aab1b37ed2</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>keras6387-fix.sh</fixtestCmd>
                <fixcommit>04bf5ac57a6071e32ffd340da0acb059912d922c</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras5975</id>
            <errormessage>MissingInputError</errormessage>
            <describe>Bidirectional wrapper produces error with any Recurrent layer with dropout or recurrent_dropout argument.Seems like wrapper is not taking good care of learning phase.</describe>
            <rootCause>1</rootCause>
            <type>IPS</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>keras5975-buggy.sh</buggytestCmd>
                <buggycommit>9217effdb445d9fd55853f716065579e2ffb9283</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>keras5975-fix.sh</fixtestCmd>
                <fixcommit>05f82d1534e93361de9181544335f9bcaceb860d</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras5840</id>
            <errormessage>AssertionError</errormessage>
            <describe>Simple merge layers that just extend _Merge and implement _merge_function report that they have multiple outputs (as many as inputs) with the same shape.</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>keras5840-buggy.sh</buggytestCmd>
                <buggycommit>9cf7f816f28a6ac7d7a4264ae015addd72e57321</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>keras5840-fix.sh</fixtestCmd>
                <fixcommit>c328a10b312ca55e949d32a4a896458fad1ebc4b</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras5108</id>
            <errormessage>ValueError</errormessage>
            <describe>Running the equivalent code in Convolution2D  for Convolution3D results in a ValueError because the input shape expected by the layer seems to be fixed to the first shape it saw.,Convolution3D fixes the input shape when the layer is built, which happens during the first call. This input shape is useful for some optimisations. Convolution2D does not fix the input shape.</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>keras5108-buggy.sh</buggytestCmd>
                <buggycommit>a5a775b79f46f3a198f71d613ccee899bec8e8ae</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>keras5108-fix.sh</fixtestCmd>
                <fixcommit>a8795957abb2750a1b38cce34e074e6a2644bc43</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras9883</id>
            <errormessage>None</errormessage>
            <describe>Conv2DTranspose infers the shape of the output using deconv_length but because the output shape of a transposed convolution is ambigous it can infer an undesired shape.</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>Keras9883-buggy.sh</buggytestCmd>
                <buggycommit>8a5d4bcc62f49d79839de9ddf8c72d97056ee522</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>Keras9883-fix.sh</fixtestCmd>
                <fixcommit>6b99d2382e53c0f6f8124ed76db399741ad64fa4</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras13073</id>
            <errormessage>None</errormessage>
            <describe>People set embedding with MAX_NUM_WORDS=3，but tokenizer return n-1 words i.e 2. </describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>Keras13073-buggy.sh</buggytestCmd>
                <buggycommit>0fc33feb5f4efe3bb823c57a8390f52932a966ab</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>Keras13073-fix.sh</fixtestCmd>
                <fixcommit>09521c9804c3ce218b44efa6d9b4af8b2c8cdd56</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>keras</name>
        <source>https://github.com/Liang813/keras</source>
        <bug>
            <id>keras2672</id>
            <errormessage>None</errormessage>
            <describe>cos mode does not carefully deal with division by zero, might be the cause of NaN. output = K.batch_dot(l1, l2, self.dot_axes) / denominator  </describe>
            <rootCause>1</rootCause>
            <type>zero division</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>Keras2672-buggy.sh</buggytestCmd>
                <buggycommit>973b5570aa4aea71323d6c08614d5e2a8f50a6ec</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>Keras2672-fix.sh</fixtestCmd>
                <fixcommit>58cbb4bf425fc80771ebfe8053cbfe928a081b61</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>CapsNet-Tensorflow</name>
        <source>https://github.com/Liang813/CapsNet-Tensorflow</source>
        <bug>
            <id>capsnet-tensorflow4</id>
            <errormessage>ValueError</errormessage>
            <describe>The reconstruction part has to take the label as input.TODO: before reconstruction the input caps2 should do masking to pick. Out the activity vector of the correct digit capsule. </describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>CapsNet-Tensorflow4-buggy.sh</buggytestCmd>
                <buggycommit>abbc810771d94bbd25a071a8aa57aabd6c4aa056</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>CapsNet-Tensorflow4-fix.sh</fixtestCmd>
                <fixcommit>a614ee5dfb22445e8e165c0dfb64c408984062f9</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>TensorFlow.NET</name>
        <source>https://github.com/Liang813/TensorFlow.NET</source>
        <bug>
            <id>tensorflow.net377</id>
            <errormessage>None</errormessage>
            <describe>Currently TensorShape only support int/long dimensions.
                We sometimes need to use an unknown dimension that represents a varying batch size that changes from run to run. </describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>TensorFlow.NET377-buggy.sh</buggytestCmd>
                <buggycommit>269611bf8652bfb031cbc84ca4bd8b995dd903e4</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>TensorFlow.NET377-fix.sh</fixtestCmd>
                <fixcommit>9e237a67334f00bc59d6dfe7f4ffb2944f95e769</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>tensorflow_scala</name>
        <source>https://github.com/Liang813/tensorflow_scala</source>
        <bug>
            <id>tensorflow_scala18</id>
            <errormessage>ValueError</errormessage>
            <describe>Trying the random distribution ops with default arguments gave  the  error.</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>tensorflow_scala18-buggy.sh</buggytestCmd>
                <buggycommit>dd021285d9ed87377b9956d8b08ac74ddecb4602</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>tensorflow_scala18-fix.sh</fixtestCmd>
                <fixcommit>83ddc58321f2e4a353b4d241bcb31ae8b4f375bd</fixcommit>
            </fixVersion>
        </bug>
    </sir>

    <sir>
        <name>probability</name>
        <source>https://github.com/Liang813/probability</source>
        <bug>
            <id>probability417</id>
            <errormessage>InvalidArgumentError</errormessage>
            <describe>LinearGaussianStateSpaceModel sample doesn't work with num_timesteps=1.It is because tf.scan in the line below gives empty tensors for latents and observations if num_timesteps=1 as self.initial_step+1 and self.final_step are equal. (because self.final_step = self.initial_step+num_timesteps)</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>probability417-buggy.sh</buggytestCmd>
                <buggycommit>499827efa11b55f44fa0d5ef0432f3e1eebeff01</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>probability417-fix.sh</fixtestCmd>
                <fixcommit>e13e623f03a8c700f4281ab43e1bc80dd903fec7</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>segmentation_models.pytorch</name>
        <source>https://github.com/Liang813/segmentation_models.pytorch</source>
        <bug>
            <id>segmentation_models.pytorch186</id>
            <errormessage>None</errormessage>
            <describe>This Bug is due to the fact that the divisor is not the same type as the dividend, resulting in the final result being 0</describe>
            <rootCause>1</rootCause>
            <type>type mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>segmentation_models.pytorch186-buggy.sh</buggytestCmd>
                <buggycommit>ecc848f7b600d0e5cc3a7bbe2a139e97de22da49</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>segmentation_models.pytorch186-fix.sh</fixtestCmd>
                <fixcommit>6884ebf7b4a995cd9f53df8fc529e0f74c438851</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>tutorials</name>
        <source>https://github.com/Liang813/tutorials</source>
        <bug>
            <id>tutorials382</id>
            <errormessage>None</errormessage>
            <describe>CrossEntropy's size does not match that needed by the mask</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>tutorials382-buggy.sh</buggytestCmd>
                <buggycommit>a46b6437b74c30b9683631942b3157788b5cb78f</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>tutorials382-fix.sh</fixtestCmd>
                <fixcommit>b93ce6e23042da153d6ee04b067e1f3d827d8189</fixcommit>
            </fixVersion>
        </bug>
    </sir>
    <sir>
        <name>pytorch-pose</name>
        <source>https://github.com/Liang813/pytorch-pose</source>
        <bug>
            <id>pytorch-pose116</id>
            <errormessage>None</errormessage>
            <describe>Input image width and height position reversed</describe>
            <rootCause>1</rootCause>
            <type>shape mismatch</type>
            <localScore></localScore>
            <fixLength></fixLength>
            <buggyVersion>
                <buggytestCmd>pytorch-pose116-buggy.sh</buggytestCmd>
                <buggycommit>e09fb262c473e705075d20e8981368e94cdfc4a3</buggycommit>
            </buggyVersion>
            <fixVersion>
                <fixtestCmd>pytorch-pose116-fix.sh</fixtestCmd>
                <fixcommit>6d48375fde4d6ff0322775b342d563bcaf3f818a</fixcommit>
            </fixVersion>
        </bug>
    </sir>
</root>